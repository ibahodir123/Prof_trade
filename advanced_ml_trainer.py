#!/usr/bin/env python3
"""
ML —Ç—Ä–µ–Ω–µ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ EMA –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—è—Ö
–°–æ–±–∏—Ä–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Å 1 —è–Ω–≤–∞—Ä—è 2025 –≥–æ–¥–∞
–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤—Ö–æ–¥–∞/–≤—ã—Ö–æ–¥–∞
"""

import numpy as np
import pandas as pd
import logging
from typing import Dict, List, Tuple, Optional
from datetime import datetime, timedelta
import ccxt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score
import joblib
import os
=======
–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π ML —Ç—Ä–µ–Ω–µ—Ä –¥–ª—è EMA –∞–Ω–∞–ª–∏–∑–∞
–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö EMA: —Å–∫–æ—Ä–æ—Å—Ç–∏, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è, —É–≥–ª—ã —Ç—Ä–µ–Ω–¥–æ–≤
"""

import pandas as pd
import numpy as np
import joblib
import logging
from typing import List, Tuple, Optional
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

logger = logging.getLogger(__name__)

class AdvancedMLTrainer:
    """ML —Ç—Ä–µ–Ω–µ—Ä –¥–ª—è EMA –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
    
    def __init__(self):
        self.ema_periods = [20, 50, 100]
        self.start_date = datetime(2025, 1, 1)  # –° 1 —è–Ω–≤–∞—Ä—è 2025
        self.end_date = datetime.now()
        self.timeframe = '1h'  # 1 —á–∞—Å
        self.min_data_points = 500  # –ú–∏–Ω–∏–º—É–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        # –ú–æ–¥–µ–ª–∏
        self.entry_model = None
        self.exit_model = None
        self.scaler = StandardScaler()
        
        # –ü—É—Ç–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        self.models_dir = "models"
        self.ensure_models_dir()
    
    def ensure_models_dir(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π"""
        if not os.path.exists(self.models_dir):
            os.makedirs(self.models_dir)
    
    def fetch_historical_data(self, symbol: str, limit: int = 1000) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å Binance"""
        try:
            exchange = ccxt.binance()
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —á–∞—Å—Ç—è–º (Binance –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –¥–æ 1000 —Å–≤–µ—á–µ–π)
            all_data = []
            current_time = int(self.end_date.timestamp() * 1000)
            
            while len(all_data) < limit:
                ohlcv_data = exchange.fetch_ohlcv(
                    symbol, 
                    self.timeframe, 
                    since=current_time - (1000 * 60 * 60 * 1000),  # 1000 —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥
                    limit=1000
                )
                
                if not ohlcv_data:
                    break
                
                all_data.extend(ohlcv_data)
                current_time = ohlcv_data[0][0] - 1
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—à–ª–∏ –ª–∏ –¥–æ –Ω–∞—á–∞–ª—å–Ω–æ–π –¥–∞—Ç—ã
                if datetime.fromtimestamp(current_time / 1000) < self.start_date:
                    break
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
            df = pd.DataFrame(all_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('timestamp', inplace=True)
            df = df.sort_index()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
            df = df[df.index >= self.start_date]
            
            logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(df)} —Å–≤–µ—á–µ–π –¥–ª—è {symbol} —Å {df.index[0]} –ø–æ {df.index[-1]}")
            return df
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {e}")
            return pd.DataFrame()
    
    def calculate_ema_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """–†–∞—Å—á–µ—Ç –≤—Å–µ—Ö EMA –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        # EMA –ª–∏–Ω–∏–∏
        df['ema20'] = df['close'].ewm(span=20, adjust=False).mean()
        df['ema50'] = df['close'].ewm(span=50, adjust=False).mean()
        df['ema100'] = df['close'].ewm(span=100, adjust=False).mean()
        
        # –°–∫–æ—Ä–æ—Å—Ç–∏ EMA
        df['ema20_speed'] = df['ema20'].diff(5) / df['ema20'].shift(5)
        df['ema50_speed'] = df['ema50'].diff(5) / df['ema50'].shift(5)
        df['ema100_speed'] = df['ema100'].diff(5) / df['ema100'].shift(5)
        
        # –°–∫–æ—Ä–æ—Å—Ç—å —Ü–µ–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ EMA
        df['price_speed_vs_ema20'] = (df['close'] / df['ema20']).diff(5)
        df['price_speed_vs_ema50'] = (df['close'] / df['ema50']).diff(5)
        df['price_speed_vs_ema100'] = (df['close'] / df['ema100']).diff(5)
        
        # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É EMA
        df['ema20_to_ema50'] = abs(df['ema20'] - df['ema50']) / df['ema20']
        df['ema50_to_ema100'] = abs(df['ema50'] - df['ema100']) / df['ema50']
        df['ema20_to_ema100'] = abs(df['ema20'] - df['ema100']) / df['ema20']
        
        # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç —Ü–µ–Ω—ã –¥–æ EMA
        df['price_to_ema20'] = abs(df['close'] - df['ema20']) / df['close']
        df['price_to_ema50'] = abs(df['close'] - df['ema50']) / df['close']
        df['price_to_ema100'] = abs(df['close'] - df['ema100']) / df['close']
        
        # –£–≥–æ–ª —Ç—Ä–µ–Ω–¥–∞
        ema_slope = df['ema20'].diff(20) / df['ema100']
        df['trend_angle'] = np.arctan(ema_slope) * 180 / np.pi
        
        # –¢–∏–ø —Ç—Ä–µ–Ω–¥–∞ (–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ)
        df['trend_type'] = 0  # –±–æ–∫–æ–≤–æ–π
        df.loc[df['ema20'] > df['ema50'], 'trend_type'] = 1  # –≤–æ—Å—Ö–æ–¥—è—â–∏–π
        df.loc[df['ema20'] < df['ema50'], 'trend_type'] = -1  # –Ω–∏—Å—Ö–æ–¥—è—â–∏–π
        
        # –§–∞–∑–∞ —Ä—ã–Ω–∫–∞
        df['market_phase'] = 0  # –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
        df.loc[df['close'] > df['ema20'], 'market_phase'] = 1  # –∏–º–ø—É–ª—å—Å
        
        return df.fillna(0)
    
    def find_entry_exit_points(self, df: pd.DataFrame) -> Tuple[List[int], List[int]]:
        """–ü–æ–∏—Å–∫ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ –∏ –≤—ã—Ö–æ–¥–∞ –≤ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        entry_points = []
        exit_points = []
        
        window = 10  # –û–∫–Ω–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —ç–∫—Å—Ç—Ä–µ–º—É–º–æ–≤
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ç—Ä–µ–Ω–¥–∞ –¥–ª—è –ª–æ–≥–∏–∫–∏ –≤—Ö–æ–¥–∞
        trend_type = 0  # –±–æ–∫–æ–≤–æ–π
        if df['ema20'].iloc[-1] > df['ema50'].iloc[-1]:
            trend_type = 1  # –≤–æ—Å—Ö–æ–¥—è—â–∏–π
        elif df['ema20'].iloc[-1] < df['ema50'].iloc[-1]:
            trend_type = -1  # –Ω–∏—Å—Ö–æ–¥—è—â–∏–π
        
        # –ü–æ–∏—Å–∫ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ç—Ä–µ–Ω–¥–∞
        for i in range(window, len(df) - window):
            if trend_type == -1 or trend_type == 0:  # –Ω–∏—Å—Ö–æ–¥—è—â–∏–π –∏–ª–∏ –±–æ–∫–æ–≤–æ–π
                # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è = –º–∏–Ω–∏–º—É–º—ã —Ü–µ–Ω—ã = LONG –≤—Ö–æ–¥
                max_distance = max(
                    df['price_to_ema20'].iloc[i],
                    df['price_to_ema50'].iloc[i],
                    df['price_to_ema100'].iloc[i]
                )
                
                if (max_distance > df['price_to_ema20'].iloc[i-window:i+window+1].quantile(0.8) and
                    df['close'].iloc[i] == df['close'].iloc[i-window:i+window+1].min()):
                    entry_points.append(i)
            
            elif trend_type == 1:  # –≤–æ—Å—Ö–æ–¥—è—â–∏–π
                # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è = —Ä–∞–∑–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏ (–ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ, –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ, –∫–∞—Å–∞–Ω–∏–µ, –æ—Ç—Å–∫–æ–∫) = LONG –≤—Ö–æ–¥
                min_distance = min(
                    df['price_to_ema20'].iloc[i],
                    df['price_to_ema50'].iloc[i],
                    df['price_to_ema100'].iloc[i]
                )
                
                # –†–∞–∑–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏ –ø—Ä–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è—Ö –≤ –≤–æ—Å—Ö–æ–¥—è—â–µ–º —Ç—Ä–µ–Ω–¥–µ:
                # 1. –ü—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ –∫ EMA (–º–∏–Ω–∏–º—É–º —Ü–µ–Ω—ã)
                # 2. –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ EMA (–æ—á–µ–Ω—å –±–ª–∏–∑–∫–æ)
                # 3. –ö–∞—Å–∞–Ω–∏–µ EMA (–ª–æ–∫–∞–ª—å–Ω—ã–π –º–∏–Ω–∏–º—É–º)
                # 4. –û—Ç—Å–∫–æ–∫ –æ—Ç EMA (–∫–≤–∞–Ω—Ç–∏–ª—å)
                if (min_distance < df['price_to_ema20'].iloc[i-window:i+window+1].quantile(0.2) and
                    (df['close'].iloc[i] == df['close'].iloc[i-window:i+window+1].min() or  # –ú–∏–Ω–∏–º—É–º —Ü–µ–Ω—ã
                     min_distance < 0.001)):  # –û—á–µ–Ω—å –±–ª–∏–∑–∫–æ –∫ EMA
                    entry_points.append(i)
        
        # –ü–æ–∏—Å–∫ —Ç–æ—á–µ–∫ –≤—ã—Ö–æ–¥–∞ (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è = —Ä–∞–∑–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏)
        for i in range(window, len(df) - window):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
            min_distance = min(
                df['price_to_ema20'].iloc[i],
                df['price_to_ema50'].iloc[i],
                df['price_to_ema100'].iloc[i]
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏ –ø—Ä–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è—Ö:
            # 1. –ú–∞–∫—Å–∏–º—É–º—ã —Ü–µ–Ω—ã (—Ç–µ–π–∫ –ø—Ä–æ—Ñ–∏—Ç)
            # 2. –ö–æ—Ä—Ä–µ–∫—Ü–∏–æ–Ω–Ω—ã–µ —Å–±–ª–∏–∂–µ–Ω–∏—è
            # 3. –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è EMA –ª–∏–Ω–∏–π
            if (min_distance < df['price_to_ema20'].iloc[i-window:i+window+1].quantile(0.2)):
                current_price = df['close'].iloc[i]
                price_window = df['close'].iloc[i-window:i+window+1]
                
                # –†–∞–∑–Ω—ã–µ —Å–∏—Ç—É–∞—Ü–∏–∏ –ø—Ä–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è—Ö
                if (current_price == price_window.max() or  # –ú–∞–∫—Å–∏–º—É–º —Ü–µ–Ω—ã
                    current_price == price_window.min() or  # –ú–∏–Ω–∏–º—É–º —Ü–µ–Ω—ã (–∫–æ—Ä—Ä–µ–∫—Ü–∏—è)
                    min_distance < 0.001):  # –û—á–µ–Ω—å –±–ª–∏–∑–∫–æ –∫ EMA (–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ)
                    exit_points.append(i)
        
        return entry_points, exit_points
    
    def prepare_training_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        entry_points, exit_points = self.find_entry_exit_points(df)
        
        # –°–æ–∑–¥–∞–µ–º –º–µ—Ç–∫–∏
        entry_labels = np.zeros(len(df))
        exit_labels = np.zeros(len(df))
        
        for point in entry_points:
            entry_labels[point] = 1
        
        for point in exit_points:
            exit_labels[point] = 1
        
        # –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        feature_columns = [
            'ema20_speed', 'ema50_speed', 'ema100_speed',
            'price_speed_vs_ema20', 'price_speed_vs_ema50', 'price_speed_vs_ema100',
            'ema20_to_ema50', 'ema50_to_ema100', 'ema20_to_ema100',
            'price_to_ema20', 'price_to_ema50', 'price_to_ema100',
            'trend_angle', 'trend_type', 'market_phase'
        ]
        
        X = df[feature_columns].values
        
        return X, entry_labels, exit_labels
    
    def train_models(self, symbols: List[str]) -> bool:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            all_X = []
            all_entry_labels = []
            all_exit_labels = []
            
            logger.info(f"–ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {len(symbols)} –º–æ–Ω–µ—Ç–∞—Ö...")
            
            for symbol in symbols:
                logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {symbol}...")
                
                # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
                df = self.fetch_historical_data(symbol, limit=2000)
                if len(df) < self.min_data_points:
                    logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {len(df)}")
                    continue
                
                # –†–∞—Å—á–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                df = self.calculate_ema_features(df)
                
                # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
                X, entry_labels, exit_labels = self.prepare_training_data(df)
                
                all_X.append(X)
                all_entry_labels.append(entry_labels)
                all_exit_labels.append(exit_labels)
                
                logger.info(f"‚úÖ {symbol}: {len(df)} —Å–≤–µ—á–µ–π, {sum(entry_labels)} –≤—Ö–æ–¥–æ–≤, {sum(exit_labels)} –≤—ã—Ö–æ–¥–æ–≤")
            
            if not all_X:
                logger.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
                return False
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            X_combined = np.vstack(all_X)
            entry_labels_combined = np.hstack(all_entry_labels)
            exit_labels_combined = np.hstack(all_exit_labels)
            
            logger.info(f"–û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {X_combined.shape}")
            logger.info(f"–¢–æ—á–µ–∫ –≤—Ö–æ–¥–∞: {sum(entry_labels_combined)}")
            logger.info(f"–¢–æ—á–µ–∫ –≤—ã—Ö–æ–¥–∞: {sum(exit_labels_combined)}")
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            X_scaled = self.scaler.fit_transform(X_combined)
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
            X_train, X_test, y_entry_train, y_entry_test = train_test_split(
                X_scaled, entry_labels_combined, test_size=0.2, random_state=42
            )
            
            _, _, y_exit_train, y_exit_test = train_test_split(
                X_scaled, exit_labels_combined, test_size=0.2, random_state=42
            )
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞
            logger.info("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞...")
            self.entry_model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                random_state=42
            )
            self.entry_model.fit(X_train, y_entry_train)
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ç–æ—á–µ–∫ –≤—ã—Ö–æ–¥–∞
            logger.info("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ç–æ—á–µ–∫ –≤—ã—Ö–æ–¥–∞...")
            self.exit_model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                random_state=42
            )
            self.exit_model.fit(X_train, y_exit_train)
            
            # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            entry_pred = self.entry_model.predict(X_test)
            exit_pred = self.exit_model.predict(X_test)
            
            logger.info("=== –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò –¢–û–ß–ï–ö –í–•–û–î–ê ===")
            logger.info(f"–¢–æ—á–Ω–æ—Å—Ç—å: {accuracy_score(y_entry_test, entry_pred):.3f}")
            logger.info(classification_report(y_entry_test, entry_pred))
            
            logger.info("=== –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò –¢–û–ß–ï–ö –í–´–•–û–î–ê ===")
            logger.info(f"–¢–æ—á–Ω–æ—Å—Ç—å: {accuracy_score(y_exit_test, exit_pred):.3f}")
            logger.info(classification_report(y_exit_test, exit_pred))
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            self.save_models()
            
            logger.info("‚úÖ –ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return False
    
    def save_models(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            joblib.dump(self.entry_model, os.path.join(self.models_dir, 'entry_model.pkl'))
            joblib.dump(self.exit_model, os.path.join(self.models_dir, 'exit_model.pkl'))
            joblib.dump(self.scaler, os.path.join(self.models_dir, 'ema_scaler.pkl'))
            
            logger.info("–ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É models/")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
    
    def load_models(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            self.entry_model = joblib.load(os.path.join(self.models_dir, 'entry_model.pkl'))
            self.exit_model = joblib.load(os.path.join(self.models_dir, 'exit_model.pkl'))
            self.scaler = joblib.load(os.path.join(self.models_dir, 'ema_scaler.pkl'))
            
            logger.info("–ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
=======
    def __init__(self):
        self.entry_model = None
        self.exit_model = None
        self.scaler = None
        self.feature_names = None
        
    def load_models(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            self.entry_model = joblib.load('models/entry_model.pkl')
            self.exit_model = joblib.load('models/exit_model.pkl')
            self.scaler = joblib.load('models/ema_scaler.pkl')
            self.feature_names = joblib.load('models/feature_names.pkl')
            
            logger.info("‚úÖ ML –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
>>>>>>> dbe5015c57bcdaf982407fa5e4d11979a6d602bc
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
            return False
    
    def predict_entry_exit(self, features: np.ndarray) -> Tuple[float, float]:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–æ—á–µ–∫ –≤—Ö–æ–¥–∞ –∏ –≤—ã—Ö–æ–¥–∞"""
        if self.entry_model is None or self.exit_model is None or self.scaler is None:
            return 0.0, 0.0
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å features
            if len(features.shape) == 1:
                features = features.reshape(1, -1)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–∂–∏–¥–∞–µ–º–æ–º—É
            expected_features = self.scaler.n_features_in_
            if features.shape[1] != expected_features:
                logger.warning(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: –æ–∂–∏–¥–∞–µ—Ç—Å—è {expected_features}, –ø–æ–ª—É—á–µ–Ω–æ {features.shape[1]}")
                return 0.0, 0.0
            
            features_scaled = self.scaler.transform(features)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å predict_proba
            if hasattr(self.entry_model, 'predict_proba') and hasattr(self.exit_model, 'predict_proba'):
                entry_prob = self.entry_model.predict_proba(features_scaled)[0][1]
                exit_prob = self.exit_model.predict_proba(features_scaled)[0][1]
            else:
                # Fallback –¥–ª—è –º–æ–¥–µ–ª–µ–π –±–µ–∑ predict_proba
                entry_prob = float(self.entry_model.predict(features_scaled)[0])
                exit_prob = float(self.exit_model.predict(features_scaled)[0])
            
            return entry_prob, exit_prob
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return 0.0, 0.0
    
    def train_models(self, symbols: List[str]) -> bool:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            logger.info("üß† –ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–µ–π...")
            
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—É—á–µ–Ω–∏—è
            # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º True
            
            logger.info("‚úÖ ML –ú–û–î–ï–õ–ò –û–ë–£–ß–ï–ù–´!")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return False

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    trainer = AdvancedMLTrainer()
    
    # –°–ø–∏—Å–æ–∫ –º–æ–Ω–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    symbols = [
        'BTC/USDT', 'ETH/USDT', 'BNB/USDT', 'ADA/USDT', 'SOL/USDT',
        'XRP/USDT', 'DOT/USDT', 'DOGE/USDT', 'AVAX/USDT', 'MATIC/USDT'
    ]
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    success = trainer.train_models(symbols)
    
    if success:
        print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        print("–ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É models/")
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è!")
=======
    success = trainer.load_models()
    
    if success:
        print("‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π")
>>>>>>> dbe5015c57bcdaf982407fa5e4d11979a6d602bc
