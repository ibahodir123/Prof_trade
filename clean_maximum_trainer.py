#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üî∫ –ß–ò–°–¢–´–ô –¢–†–ï–ù–ï–† –ú–ê–ö–°–ò–ú–£–ú–û–í
–û–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –Ω–∞ EMA-–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö –±–µ–∑ RSI
"""

import ccxt
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import pickle
import json
from sklearn.ensemble import RandomForestClassifier
import warnings
warnings.filterwarnings('ignore')

class CleanMaximumTrainer:
    def __init__(self):
        self.symbols = ['BTC/USDT', 'ETH/USDT', 'ADA/USDT', 'XRP/USDT', 'SOL/USDT']
        self.maximums_database = []
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –º–∞–∫—Å–∏–º—É–º–æ–≤
        self.min_lookback = 6
        self.min_drop_threshold = 2.0
        self.max_duration = 48
        self.verification_hours = 6
        
        print("üî∫ –ß–ò–°–¢–´–ô –¢–†–ï–ù–ï–† –ú–ê–ö–°–ò–ú–£–ú–û–í (–ë–ï–ó RSI)")
        print("üìä –¢–æ–ª—å–∫–æ EMA-–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")
        print("=" * 50)
        
    def get_recent_data(self, symbol: str, days: int = 30) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            print(f"üìä –ó–∞–≥—Ä—É–∂–∞—é {symbol} –∑–∞ {days} –¥–Ω–µ–π...")
            exchange = ccxt.binance()
            
            end_time = datetime.now()
            start_time = end_time - timedelta(days=days)
            
            since = int(start_time.timestamp() * 1000)
            end_ts = int(end_time.timestamp() * 1000)
            
            all_ohlcv = []
            current_since = since
            
            while current_since < end_ts:
                try:
                    ohlcv = exchange.fetch_ohlcv(symbol, '1h', since=current_since, limit=1000)
                    if not ohlcv:
                        break
                    
                    all_ohlcv.extend(ohlcv)
                    current_since = ohlcv[-1][0] + 1
                    
                    if current_since > end_ts:
                        break
                        
                    time.sleep(0.1)
                    
                except Exception as e:
                    break
            
            if not all_ohlcv:
                return pd.DataFrame()
            
            all_ohlcv = [candle for candle in all_ohlcv if candle[0] <= end_ts]
            
            df = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df = df.set_index('timestamp')
            
            print(f"   ‚úÖ {len(df)} —Å–≤–µ—á–µ–π")
            return df
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
            return pd.DataFrame()
    
    def prepare_clean_maximum_features(self, df: pd.DataFrame, max_idx: int) -> dict:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —á–∏—Å—Ç—ã—Ö EMA-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º—É–º–∞"""
        try:
            if max_idx < 50 or max_idx >= len(df) - 6:
                return None
            
            # –î–æ–±–∞–≤–ª—è–µ–º EMA
            df['ema_20'] = df['close'].ewm(span=20).mean()
            df['ema_50'] = df['close'].ewm(span=50).mean()
            df['ema_100'] = df['close'].ewm(span=100).mean()
            
            current = df.iloc[max_idx]
            prev = df.iloc[max_idx - 1]
            prev_2 = df.iloc[max_idx - 2]
            
            # üî∫ –¢–û–õ–¨–ö–û EMA-–û–°–ù–û–í–ê–ù–ù–´–ï –ü–†–ò–ó–ù–ê–ö–ò
            
            # 1. –°–∫–æ—Ä–æ—Å—Ç–∏ (–Ω–∞ –º–∞–∫—Å–∏–º—É–º–µ)
            price_velocity = (current['close'] - prev['close']) / prev['close']
            ema20_velocity = (current['ema_20'] - prev['ema_20']) / prev['ema_20']
            ema50_velocity = (current['ema_50'] - prev['ema_50']) / prev['ema_50']
            ema100_velocity = (current['ema_100'] - prev['ema_100']) / prev['ema_100']
            
            # 2. –£—Å–∫–æ—Ä–µ–Ω–∏–µ (–∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –º–∞–∫—Å–∏–º—É–º–æ–≤!)
            prev_price_velocity = (prev['close'] - prev_2['close']) / prev_2['close']
            price_acceleration = price_velocity - prev_price_velocity
            
            # 3. –†–∞—Å—Å—Ç–æ—è–Ω–∏—è (—Ü–µ–Ω–∞ –í–´–®–ï EMA - –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å)
            price_distance_ema20 = (current['close'] - current['ema_20']) / current['ema_20']
            price_distance_ema50 = (current['close'] - current['ema_50']) / current['ema_50']
            price_distance_ema100 = (current['close'] - current['ema_100']) / current['ema_100']
            
            # 4. –£–≥–ª—ã —Ç—Ä–µ–Ω–¥–∞ (–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ = –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å)
            ema20_angle = ema20_velocity * 100
            ema50_angle = ema50_velocity * 100
            ema100_angle = ema100_velocity * 100
            
            # 5. –û–±—ä–µ–º
            avg_volume = df['volume'].iloc[max_idx-20:max_idx].mean()
            volume_ratio = current['volume'] / avg_volume if avg_volume > 0 else 1
            
            # 6. –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
            volatility = df['close'].iloc[max_idx-20:max_idx].std() / df['close'].iloc[max_idx-20:max_idx].mean()
            
            # 7. –ò–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
            prev_dist_ema20 = (prev['close'] - prev['ema_20']) / prev['ema_20']
            prev_dist_ema50 = (prev['close'] - prev['ema_50']) / prev['ema_50']
            distance_change_ema20 = price_distance_ema20 - prev_dist_ema20
            distance_change_ema50 = price_distance_ema50 - prev_dist_ema50
            
            # 8. –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–µ–π
            velocity_ratio_price_ema20 = price_velocity / ema20_velocity if ema20_velocity != 0 else 0
            velocity_ratio_ema20_ema50 = ema20_velocity / ema50_velocity if ema50_velocity != 0 else 0
            velocity_ratio_ema50_ema100 = ema50_velocity / ema100_velocity if ema100_velocity != 0 else 0
            
            # 9. –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É EMA
            ema20_to_ema50 = (current['ema_20'] - current['ema_50']) / current['ema_50']
            ema50_to_ema100 = (current['ema_50'] - current['ema_100']) / current['ema_100']
            ema20_to_ema100 = (current['ema_20'] - current['ema_100']) / current['ema_100']
            
            features = {
                # –°–∫–æ—Ä–æ—Å—Ç–∏
                'price_velocity': price_velocity,
                'ema20_velocity': ema20_velocity,
                'ema50_velocity': ema50_velocity,
                'ema100_velocity': ema100_velocity,
                
                # –£—Å–∫–æ—Ä–µ–Ω–∏–µ
                'price_acceleration': price_acceleration,
                
                # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç EMA
                'price_distance_ema20': price_distance_ema20,
                'price_distance_ema50': price_distance_ema50,
                'price_distance_ema100': price_distance_ema100,
                
                # –£–≥–ª—ã
                'ema20_angle': ema20_angle,
                'ema50_angle': ema50_angle,
                'ema100_angle': ema100_angle,
                
                # –û–±—ä–µ–º –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
                'volume_ratio': volume_ratio,
                'volatility': volatility,
                
                # –ò–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
                'distance_change_ema20': distance_change_ema20,
                'distance_change_ema50': distance_change_ema50,
                
                # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–µ–π
                'velocity_ratio_price_ema20': velocity_ratio_price_ema20,
                'velocity_ratio_ema20_ema50': velocity_ratio_ema20_ema50,
                'velocity_ratio_ema50_ema100': velocity_ratio_ema50_ema100,
                
                # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É EMA
                'ema20_to_ema50': ema20_to_ema50,
                'ema50_to_ema100': ema50_to_ema100,
                'ema20_to_ema100': ema20_to_ema100
            }
            
            return features
            
        except Exception:
            return None
    
    def find_clean_maximums(self, df: pd.DataFrame, symbol: str):
        """–ü–æ–∏—Å–∫ —á–∏—Å—Ç—ã—Ö –º–∞–∫—Å–∏–º—É–º–æ–≤"""
        print(f"üî∫ –ò—â—É –º–∞–∫—Å–∏–º—É–º—ã –≤ {symbol}...")
        
        maximums_found = 0
        
        for i in range(50, len(df) - 6):
            try:
                current_high = df.iloc[i]['high']
                current_time = df.index[i]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ª–æ–∫–∞–ª—å–Ω—ã–π –º–∞–∫—Å–∏–º—É–º
                is_maximum = True
                for j in range(max(0, i-self.min_lookback), min(len(df), i+self.min_lookback+1)):
                    if j != i and df.iloc[j]['high'] >= current_high:
                        is_maximum = False
                        break
                
                if not is_maximum:
                    continue
                
                # –ò—â–µ–º –º–∏–Ω–∏–º—É–º –≤ –±—É–¥—É—â–µ–º
                min_price = current_high
                min_idx = i
                min_time = current_time
                
                for j in range(i+1, min(len(df), i+49)):
                    if df.iloc[j]['low'] < min_price:
                        min_price = df.iloc[j]['low']
                        min_idx = j
                        min_time = df.index[j]
                
                drop_percent = ((min_price - current_high) / current_high) * 100
                duration_hours = (min_time - current_time).total_seconds() / 3600
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
                if (drop_percent <= -self.min_drop_threshold and 
                    duration_hours <= self.max_duration):
                    
                    features = self.prepare_clean_maximum_features(df, i)
                    
                    if features:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                        if (features['price_distance_ema20'] > 0.01 and  # –¶–µ–Ω–∞ –≤—ã—à–µ EMA20
                            features['volume_ratio'] > 0.5 and  # –û–±—ä–µ–º –Ω–µ —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∏–π
                            features['ema20_angle'] > 0):  # EMA20 –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤–≤–µ—Ä—Ö
                            
                            maximum = {
                                'symbol': symbol,
                                'entry_time': current_time,
                                'exit_time': min_time,
                                'entry_price': current_high,
                                'exit_price': min_price,
                                'drop_percent': drop_percent,
                                'duration_hours': duration_hours,
                                'features': features,
                                'is_profitable_exit': drop_percent <= -3.0,
                                'data_age_hours': (datetime.now() - current_time).total_seconds() / 3600
                            }
                            
                            self.maximums_database.append(maximum)
                            maximums_found += 1
                            
            except Exception:
                continue
        
        print(f"   ‚úÖ {maximums_found} –º–∞–∫—Å–∏–º—É–º–æ–≤")
    
    def collect_clean_data(self):
        """–°–±–æ—Ä —á–∏—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("\nüìö –°–ë–û–† –ß–ò–°–¢–´–• –î–ê–ù–ù–´–• –ú–ê–ö–°–ò–ú–£–ú–û–í")
        print("-" * 40)
        
        self.maximums_database = []
        
        for i, symbol in enumerate(self.symbols):
            print(f"[{i+1}/{len(self.symbols)}] {symbol}")
            df = self.get_recent_data(symbol, days=30)
            if not df.empty:
                self.find_clean_maximums(df, symbol)
            time.sleep(0.5)
        
        print(f"\nüìä –ò–¢–û–ì–û –ù–ê–ô–î–ï–ù–û: {len(self.maximums_database)} –º–∞–∫—Å–∏–º—É–º–æ–≤")
        
        if self.maximums_database:
            drops = [m['drop_percent'] for m in self.maximums_database]
            durations = [m['duration_hours'] for m in self.maximums_database]
            good_exits = [m for m in self.maximums_database if m['is_profitable_exit']]
            
            print(f"üìâ –°—Ä–µ–¥–Ω–µ–µ –ø–∞–¥–µ–Ω–∏–µ: {np.mean(drops):.2f}%")
            print(f"‚è±Ô∏è –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {np.mean(durations):.1f} —á–∞—Å–æ–≤")
            print(f"üéØ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ: {np.min(drops):.2f}%")
            print(f"‚úÖ –•–æ—Ä–æ—à–∏—Ö –≤—ã—Ö–æ–¥–æ–≤: {len(good_exits)} ({len(good_exits)/len(self.maximums_database)*100:.1f}%)")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
            symbol_stats = {}
            for maximum in self.maximums_database:
                symbol = maximum['symbol']
                if symbol not in symbol_stats:
                    symbol_stats[symbol] = {'count': 0, 'avg_drop': 0, 'good_exits': 0, 'max_drop': 0}
                symbol_stats[symbol]['count'] += 1
                symbol_stats[symbol]['avg_drop'] += maximum['drop_percent']
                if maximum['is_profitable_exit']:
                    symbol_stats[symbol]['good_exits'] += 1
                if maximum['drop_percent'] < symbol_stats[symbol]['max_drop']:
                    symbol_stats[symbol]['max_drop'] = maximum['drop_percent']
            
            print(f"\nüèÜ –ü–æ —Å–∏–º–≤–æ–ª–∞–º:")
            for symbol, stats in sorted(symbol_stats.items(), key=lambda x: abs(x[1]['avg_drop']/x[1]['count']), reverse=True):
                avg_drop = stats['avg_drop'] / stats['count']
                exit_rate = stats['good_exits'] / stats['count'] * 100
                print(f"   {symbol}: {stats['count']} –º–∞–∫—Å–∏–º—É–º–æ–≤, {avg_drop:.2f}% —Å—Ä–µ–¥–Ω–µ–µ –ø–∞–¥–µ–Ω–∏–µ, {exit_rate:.1f}% —Ö–æ—Ä–æ—à–∏—Ö –≤—ã—Ö–æ–¥–æ–≤")
    
    def analyze_clean_patterns(self):
        """–ê–Ω–∞–ª–∏–∑ —á–∏—Å—Ç—ã—Ö –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–µ–π"""
        print("\nüîç –ê–ù–ê–õ–ò–ó –ß–ò–°–¢–´–• –ó–ê–ö–û–ù–û–ú–ï–†–ù–û–°–¢–ï–ô")
        print("-" * 40)
        
        if len(self.maximums_database) < 5:
            print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_stats = {}
        feature_names = list(self.maximums_database[0]['features'].keys())
        
        for feature_name in feature_names:
            good_exit_values = []
            bad_exit_values = []
            
            for maximum in self.maximums_database:
                value = maximum['features'][feature_name]
                if maximum['is_profitable_exit']:
                    good_exit_values.append(value)
                else:
                    bad_exit_values.append(value)
            
            if good_exit_values and bad_exit_values:
                feature_stats[feature_name] = {
                    'good_exit_mean': np.mean(good_exit_values),
                    'good_exit_std': np.std(good_exit_values),
                    'bad_exit_mean': np.mean(bad_exit_values),
                    'bad_exit_std': np.std(bad_exit_values),
                    'difference': abs(np.mean(good_exit_values) - np.mean(bad_exit_values))
                }
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–Ω–æ—Å—Ç–∏
        feature_importance = sorted(feature_stats.items(), key=lambda x: x[1]['difference'], reverse=True)
        
        print("üèÜ –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í (—Ç–æ–ª—å–∫–æ EMA-–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ):")
        for feature_name, stats in feature_importance:
            print(f"   {feature_name}:")
            print(f"     –•–æ—Ä–æ—à–∏–µ –≤—ã—Ö–æ–¥—ã: {stats['good_exit_mean']:.4f} ¬± {stats['good_exit_std']:.4f}")
            print(f"     –ü–ª–æ—Ö–∏–µ –≤—ã—Ö–æ–¥—ã: {stats['bad_exit_mean']:.4f} ¬± {stats['bad_exit_std']:.4f}")
            print(f"     –†–∞–∑–Ω–æ—Å—Ç—å: {stats['difference']:.4f}")
            print()
    
    def train_clean_model(self):
        """–û–±—É—á–µ–Ω–∏–µ —á–∏—Å—Ç–æ–π –º–æ–¥–µ–ª–∏"""
        print("\nüß† –û–ë–£–ß–ï–ù–ò–ï –ß–ò–°–¢–û–ô –ú–û–î–ï–õ–ò")
        print("-" * 30)
        
        if len(self.maximums_database) < 10:
            print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return None
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        X = []
        y = []
        
        feature_names = list(self.maximums_database[0]['features'].keys())
        
        for maximum in self.maximums_database:
            features_list = [maximum['features'][name] for name in feature_names]
            X.append(features_list)
            y.append(1 if maximum['is_profitable_exit'] else 0)
        
        X = np.array(X)
        y = np.array(y)
        
        print(f"üìä –î–∞–Ω–Ω—ã—Ö: {len(X)} –æ–±—Ä–∞–∑—Ü–æ–≤, {len(feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        print(f"‚úÖ –•–æ—Ä–æ—à–∏—Ö –≤—ã—Ö–æ–¥–æ–≤: {sum(y)} ({sum(y)/len(y)*100:.1f}%)")
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=8)
        model.fit(X, y)
        
        # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        importances = model.feature_importances_
        feature_importance = list(zip(feature_names, importances))
        feature_importance.sort(key=lambda x: x[1], reverse=True)
        
        print(f"\nüèÜ –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í (—á–∏—Å—Ç–∞—è –º–æ–¥–µ–ª—å):")
        for name, importance in feature_importance:
            print(f"   {name}: {importance:.4f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_filename = f'clean_maximum_model_{timestamp}.pkl'
        feature_filename = f'clean_maximum_features_{timestamp}.pkl'
        
        with open(model_filename, 'wb') as f:
            pickle.dump(model, f)
        
        with open(feature_filename, 'wb') as f:
            pickle.dump(feature_names, f)
        
        print(f"\nüíæ –ß–∏—Å—Ç–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_filename}")
        print(f"üíæ –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {feature_filename}")
        
        return model, feature_names
    
    def run_clean_analysis(self):
        """–ó–∞–ø—É—Å–∫ —á–∏—Å—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        print("üöÄ –ß–ò–°–¢–´–ô –ê–ù–ê–õ–ò–ó –ú–ê–ö–°–ò–ú–£–ú–û–í (–ë–ï–ó RSI)")
        print("=" * 50)
        
        # 1. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
        self.collect_clean_data()
        
        if not self.maximums_database:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ")
            return
        
        # 2. –ê–Ω–∞–ª–∏–∑ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–µ–π
        self.analyze_clean_patterns()
        
        # 3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model_result = self.train_clean_model()
        
        print(f"\n‚úÖ –ß–ò–°–¢–´–ô –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù!")
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(self.maximums_database)} –º–∞–∫—Å–∏–º—É–º–æ–≤")
        
        if model_result:
            print(f"üß† –ß–∏—Å—Ç–∞—è –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")

if __name__ == "__main__":
    trainer = CleanMaximumTrainer()
    trainer.run_clean_analysis()
