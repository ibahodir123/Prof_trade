#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üìö –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–ô –¢–†–ï–ù–ï–† –î–õ–Ø –î–û–õ–ì–û–°–†–û–ß–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø
–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö —Å 2017 –ø–æ 2024 –≥–æ–¥ (–º–∞–∫—Å–∏–º—É–º –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import ccxt
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import pickle
import json
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

class HistoricalTrainer:
    def __init__(self):
        self.symbols = ['BTC/USDT', 'ETH/USDT', 'ADA/USDT', 'XRP/USDT', 'SOL/USDT']
        
        # –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        self.minimums_database = []
        self.maximums_database = []
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
        self.min_lookback = 6
        self.min_profit_threshold = 2.0
        self.max_duration = 72  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        self.verification_hours = 12
        
        # –ü–µ—Ä–∏–æ–¥—ã –æ–±—É—á–µ–Ω–∏—è
        self.training_start = datetime(2022, 1, 1)  # –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è —Å 2022
        self.training_end = datetime(2024, 12, 31)  # –ö–æ–Ω–µ—Ü –æ–±—É—á–µ–Ω–∏—è
        self.testing_start = datetime(2025, 1, 1)   # –ù–∞—á–∞–ª–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        
        print("üìö –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–ô –¢–†–ï–ù–ï–† –î–õ–Ø –î–û–õ–ì–û–°–†–û–ß–ù–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
        print("üìä –ü–µ—Ä–∏–æ–¥ –æ–±—É—á–µ–Ω–∏—è: 2022-2024")
        print("üß™ –ü–µ—Ä–∏–æ–¥ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: 2025")
        print("=" * 60)
    
    def get_historical_data(self, symbol: str, start_date: datetime, end_date: datetime) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            print(f"üìä –ó–∞–≥—Ä—É–∂–∞—é {symbol} —Å {start_date.strftime('%Y-%m-%d')} –ø–æ {end_date.strftime('%Y-%m-%d')}...")
            exchange = ccxt.binance()
            
            since = int(start_date.timestamp() * 1000)
            end_ts = int(end_date.timestamp() * 1000)
            
            all_ohlcv = []
            current_since = since
            
            while current_since < end_ts:
                try:
                    ohlcv = exchange.fetch_ohlcv(symbol, '1h', since=current_since, limit=1000)
                    if not ohlcv:
                        break
                    
                    all_ohlcv.extend(ohlcv)
                    current_since = ohlcv[-1][0] + 1
                    
                    if current_since > end_ts:
                        break
                        
                    time.sleep(0.1)  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤
                    
                except Exception as e:
                    print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
                    break
            
            if not all_ohlcv:
                return pd.DataFrame()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫–æ–Ω–µ—á–Ω–æ–π –¥–∞—Ç–µ
            all_ohlcv = [candle for candle in all_ohlcv if candle[0] <= end_ts]
            
            df = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df = df.set_index('timestamp')
            
            # –î–æ–±–∞–≤–ª—è–µ–º EMA
            df['ema_20'] = df['close'].ewm(span=20).mean()
            df['ema_50'] = df['close'].ewm(span=50).mean()
            df['ema_100'] = df['close'].ewm(span=100).mean()
            
            print(f"   ‚úÖ {len(df)} —Å–≤–µ—á–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
            return df
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")
            return pd.DataFrame()
    
    def prepare_historical_minimum_features(self, df: pd.DataFrame, min_idx: int) -> dict:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –º–∏–Ω–∏–º—É–º–æ–≤"""
        try:
            if min_idx < 50 or min_idx >= len(df) - 6:
                return None
            
            current = df.iloc[min_idx]
            prev = df.iloc[min_idx - 1]
            prev_2 = df.iloc[min_idx - 2]
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            features = {
                # –°–∫–æ—Ä–æ—Å—Ç–∏
                'price_velocity': (current['close'] - prev['close']) / prev['close'],
                'ema20_velocity': (current['ema_20'] - prev['ema_20']) / prev['ema_20'],
                'ema50_velocity': (current['ema_50'] - prev['ema_50']) / prev['ema_50'],
                'ema100_velocity': (current['ema_100'] - prev['ema_100']) / prev['ema_100'],
                
                # –£—Å–∫–æ—Ä–µ–Ω–∏–µ
                'price_acceleration': ((current['close'] - prev['close']) / prev['close']) - 
                                   ((prev['close'] - prev_2['close']) / prev_2['close']),
                
                # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç EMA
                'price_distance_ema20': (current['close'] - current['ema_20']) / current['ema_20'],
                'price_distance_ema50': (current['close'] - current['ema_50']) / current['ema_50'],
                'price_distance_ema100': (current['close'] - current['ema_100']) / current['ema_100'],
                
                # –£–≥–ª—ã
                'ema20_angle': ((current['ema_20'] - prev['ema_20']) / prev['ema_20']) * 100,
                'ema50_angle': ((current['ema_50'] - prev['ema_50']) / prev['ema_50']) * 100,
                'ema100_angle': ((current['ema_100'] - prev['ema_100']) / prev['ema_100']) * 100,
                
                # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
                'volatility': df['close'].iloc[min_idx-20:min_idx].std() / df['close'].iloc[min_idx-20:min_idx].mean(),
                
                # –û–±—ä–µ–º (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
                'volume_ratio': current['volume'] / df['volume'].iloc[min_idx-20:min_idx].mean() if df['volume'].iloc[min_idx-20:min_idx].mean() > 0 else 1,
                
                # –ò–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
                'distance_change_ema20': (current['close'] - current['ema_20']) / current['ema_20'] - 
                                       (prev['close'] - prev['ema_20']) / prev['ema_20'],
                'distance_change_ema50': (current['close'] - current['ema_50']) / current['ema_50'] - 
                                       (prev['close'] - prev['ema_50']) / prev['ema_50'],
                
                # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–µ–π
                'velocity_ratio_price_ema20': (current['close'] - prev['close']) / prev['close'] / 
                                            ((current['ema_20'] - prev['ema_20']) / prev['ema_20']) if (current['ema_20'] - prev['ema_20']) / prev['ema_20'] != 0 else 0,
                'velocity_ratio_ema20_ema50': ((current['ema_20'] - prev['ema_20']) / prev['ema_20']) / 
                                            ((current['ema_50'] - prev['ema_50']) / prev['ema_50']) if (current['ema_50'] - prev['ema_50']) / prev['ema_50'] != 0 else 0,
                
                # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É EMA
                'ema20_to_ema50': (current['ema_20'] - current['ema_50']) / current['ema_50'],
                'ema50_to_ema100': (current['ema_50'] - current['ema_100']) / current['ema_100'],
                'ema20_to_ema100': (current['ema_20'] - current['ema_100']) / current['ema_100']
            }
            
            return features
            
        except Exception:
            return None
    
    def prepare_historical_maximum_features(self, df: pd.DataFrame, max_idx: int) -> dict:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –º–∞–∫—Å–∏–º—É–º–æ–≤"""
        try:
            if max_idx < 50 or max_idx >= len(df) - 6:
                return None
            
            current = df.iloc[max_idx]
            prev = df.iloc[max_idx - 1]
            prev_2 = df.iloc[max_idx - 2]
            
            # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–∞–∫—Å–∏–º—É–º–æ–≤
            price_velocity = (current['close'] - prev['close']) / prev['close']
            ema20_velocity = (current['ema_20'] - prev['ema_20']) / prev['ema_20']
            ema50_velocity = (current['ema_50'] - prev['ema_50']) / prev['ema_50']
            ema100_velocity = (current['ema_100'] - prev['ema_100']) / prev['ema_100']
            
            features = {
                # –°–∫–æ—Ä–æ—Å—Ç–∏
                'price_velocity': price_velocity,
                'ema20_velocity': ema20_velocity,
                'ema50_velocity': ema50_velocity,
                'ema100_velocity': ema100_velocity,
                
                # –£—Å–∫–æ—Ä–µ–Ω–∏–µ
                'price_acceleration': price_velocity - ((prev['close'] - prev_2['close']) / prev_2['close']),
                
                # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –æ—Ç EMA
                'price_distance_ema20': (current['close'] - current['ema_20']) / current['ema_20'],
                'price_distance_ema50': (current['close'] - current['ema_50']) / current['ema_50'],
                'price_distance_ema100': (current['close'] - current['ema_100']) / current['ema_100'],
                
                # –£–≥–ª—ã
                'ema20_angle': ema20_velocity * 100,
                'ema50_angle': ema50_velocity * 100,
                'ema100_angle': ema100_velocity * 100,
                
                # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
                'volatility': df['close'].iloc[max_idx-20:max_idx].std() / df['close'].iloc[max_idx-20:max_idx].mean(),
                
                # –û–±—ä–µ–º
                'volume_ratio': current['volume'] / df['volume'].iloc[max_idx-20:max_idx].mean() if df['volume'].iloc[max_idx-20:max_idx].mean() > 0 else 1,
                
                # –ò–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
                'distance_change_ema20': (current['close'] - current['ema_20']) / current['ema_20'] - 
                                       (prev['close'] - prev['ema_20']) / prev['ema_20'],
                'distance_change_ema50': (current['close'] - current['ema_50']) / current['ema_50'] - 
                                       (prev['close'] - prev['ema_50']) / prev['ema_50'],
                
                # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–µ–π
                'velocity_ratio_price_ema20': price_velocity / ema20_velocity if ema20_velocity != 0 else 0,
                'velocity_ratio_ema20_ema50': ema20_velocity / ema50_velocity if ema50_velocity != 0 else 0,
                'velocity_ratio_ema50_ema100': ema50_velocity / ema100_velocity if ema100_velocity != 0 else 0,
                
                # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É EMA
                'ema20_to_ema50': (current['ema_20'] - current['ema_50']) / current['ema_50'],
                'ema50_to_ema100': (current['ema_50'] - current['ema_100']) / current['ema_100'],
                'ema20_to_ema100': (current['ema_20'] - current['ema_100']) / current['ema_100'],
                
                # –ù–∞–∫–ª–æ–Ω—ã EMA
                'ema20_slope': (current['ema_20'] - df.iloc[max_idx-5]['ema_20']) / 5,
                'ema50_slope': (current['ema_50'] - df.iloc[max_idx-5]['ema_50']) / 5,
                'ema100_slope': (current['ema_100'] - df.iloc[max_idx-5]['ema_100']) / 5,
                
                # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è EMA
                'ema20_ema50_ratio': current['ema_20'] / current['ema_50'],
                'ema50_ema100_ratio': current['ema_50'] / current['ema_100'],
                'ema20_ema100_ratio': current['ema_20'] / current['ema_100']
            }
            
            return features
            
        except Exception:
            return None
    
    def find_historical_minimums(self, df: pd.DataFrame, symbol: str):
        """–ü–æ–∏—Å–∫ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –º–∏–Ω–∏–º—É–º–æ–≤"""
        print(f"üéØ –ò—â—É –º–∏–Ω–∏–º—É–º—ã –≤ {symbol}...")
        
        minimums_found = 0
        
        for i in range(100, len(df) - 6):
            try:
                current_low = df.iloc[i]['low']
                current_time = df.index[i]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ª–æ–∫–∞–ª—å–Ω—ã–π –º–∏–Ω–∏–º—É–º
                is_minimum = True
                for j in range(max(0, i-self.min_lookback), min(len(df), i+self.min_lookback+1)):
                    if j != i and df.iloc[j]['low'] <= current_low:
                        is_minimum = False
                        break
                
                if not is_minimum:
                    continue
                
                # –ò—â–µ–º –º–∞–∫—Å–∏–º—É–º –≤ –±—É–¥—É—â–µ–º
                max_price = current_low
                max_idx = i
                max_time = current_time
                
                for j in range(i+1, min(len(df), i+73)):  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–æ–∏—Å–∫ –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                    if df.iloc[j]['high'] > max_price:
                        max_price = df.iloc[j]['high']
                        max_idx = j
                        max_time = df.index[j]
                
                profit_percent = ((max_price - current_low) / current_low) * 100
                duration_hours = (max_time - current_time).total_seconds() / 3600
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
                if (profit_percent >= self.min_profit_threshold and 
                    duration_hours <= self.max_duration):
                    
                    features = self.prepare_historical_minimum_features(df, i)
                    
                    if features:
                        minimum = {
                            'symbol': symbol,
                            'entry_time': current_time,
                            'exit_time': max_time,
                            'entry_price': current_low,
                            'exit_price': max_price,
                            'profit_percent': profit_percent,
                            'duration_hours': duration_hours,
                            'features': features,
                            'is_profitable': profit_percent >= 3.0,
                            'data_age_hours': (datetime.now() - current_time).total_seconds() / 3600
                        }
                        
                        self.minimums_database.append(minimum)
                        minimums_found += 1
                        
            except Exception:
                continue
        
        print(f"   ‚úÖ {minimums_found} –º–∏–Ω–∏–º—É–º–æ–≤")
    
    def find_historical_maximums(self, df: pd.DataFrame, symbol: str):
        """–ü–æ–∏—Å–∫ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –º–∞–∫—Å–∏–º—É–º–æ–≤"""
        print(f"üî∫ –ò—â—É –º–∞–∫—Å–∏–º—É–º—ã –≤ {symbol}...")
        
        maximums_found = 0
        
        for i in range(100, len(df) - 6):
            try:
                current_high = df.iloc[i]['high']
                current_time = df.index[i]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ª–æ–∫–∞–ª—å–Ω—ã–π –º–∞–∫—Å–∏–º—É–º
                is_maximum = True
                for j in range(max(0, i-self.min_lookback), min(len(df), i+self.min_lookback+1)):
                    if j != i and df.iloc[j]['high'] >= current_high:
                        is_maximum = False
                        break
                
                if not is_maximum:
                    continue
                
                # –ò—â–µ–º –º–∏–Ω–∏–º—É–º –≤ –±—É–¥—É—â–µ–º
                min_price = current_high
                min_idx = i
                min_time = current_time
                
                for j in range(i+1, min(len(df), i+73)):  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–æ–∏—Å–∫ –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                    if df.iloc[j]['low'] < min_price:
                        min_price = df.iloc[j]['low']
                        min_idx = j
                        min_time = df.index[j]
                
                drop_percent = ((min_price - current_high) / current_high) * 100
                duration_hours = (min_time - current_time).total_seconds() / 3600
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
                if (drop_percent <= -self.min_profit_threshold and 
                    duration_hours <= self.max_duration):
                    
                    features = self.prepare_historical_maximum_features(df, i)
                    
                    if features:
                        maximum = {
                            'symbol': symbol,
                            'entry_time': current_time,
                            'exit_time': min_time,
                            'entry_price': current_high,
                            'exit_price': min_price,
                            'drop_percent': drop_percent,
                            'duration_hours': duration_hours,
                            'features': features,
                            'is_profitable_exit': drop_percent <= -3.0,
                            'data_age_hours': (datetime.now() - current_time).total_seconds() / 3600
                        }
                        
                        self.maximums_database.append(maximum)
                        maximums_found += 1
                        
            except Exception:
                continue
        
        print(f"   ‚úÖ {maximums_found} –º–∞–∫—Å–∏–º—É–º–æ–≤")
    
    def collect_historical_data(self):
        """–°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print("\nüìö –°–ë–û–† –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–• –î–ê–ù–ù–´–•")
        print("-" * 40)
        
        self.minimums_database = []
        self.maximums_database = []
        
        for i, symbol in enumerate(self.symbols):
            print(f"[{i+1}/{len(self.symbols)}] {symbol}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≥–æ–¥–∞–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            for year in range(2022, 2025):
                start_date = datetime(year, 1, 1)
                end_date = datetime(year, 12, 31)
                
                df = self.get_historical_data(symbol, start_date, end_date)
                if not df.empty:
                    self.find_historical_minimums(df, symbol)
                    self.find_historical_maximums(df, symbol)
                
                time.sleep(1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –≥–æ–¥–∞–º–∏
        
        print(f"\nüìä –ò–¢–û–ì–û –ù–ê–ô–î–ï–ù–û:")
        print(f"üéØ –ú–∏–Ω–∏–º—É–º–æ–≤: {len(self.minimums_database)}")
        print(f"üî∫ –ú–∞–∫—Å–∏–º—É–º–æ–≤: {len(self.maximums_database)}")
        
        if self.minimums_database:
            profits = [m['profit_percent'] for m in self.minimums_database]
            profitable = [m for m in self.minimums_database if m['is_profitable']]
            print(f"üìà –°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–±—ã–ª—å: {np.mean(profits):.2f}%")
            print(f"‚úÖ –ü—Ä–∏–±—ã–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–æ–≤: {len(profitable)} ({len(profitable)/len(self.minimums_database)*100:.1f}%)")
        
        if self.maximums_database:
            drops = [m['drop_percent'] for m in self.maximums_database]
            good_exits = [m for m in self.maximums_database if m['is_profitable_exit']]
            print(f"üìâ –°—Ä–µ–¥–Ω–µ–µ –ø–∞–¥–µ–Ω–∏–µ: {np.mean(drops):.2f}%")
            print(f"‚úÖ –•–æ—Ä–æ—à–∏—Ö –≤—ã—Ö–æ–¥–æ–≤: {len(good_exits)} ({len(good_exits)/len(self.maximums_database)*100:.1f}%)")
    
    def train_historical_models(self):
        """–û–±—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π"""
        print("\nüß† –û–ë–£–ß–ï–ù–ò–ï –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–• –ú–û–î–ï–õ–ï–ô")
        print("-" * 40)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –º–∏–Ω–∏–º—É–º–æ–≤
        if len(self.minimums_database) >= 50:
            print("üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –º–∏–Ω–∏–º—É–º–æ–≤...")
            
            X_min = []
            y_min = []
            feature_names_min = list(self.minimums_database[0]['features'].keys())
            
            for minimum in self.minimums_database:
                features_list = [minimum['features'][name] for name in feature_names_min]
                X_min.append(features_list)
                y_min.append(1 if minimum['is_profitable'] else 0)
            
            X_min = np.array(X_min)
            y_min = np.array(y_min)
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
            scaler_min = StandardScaler()
            X_min_scaled = scaler_min.fit_transform(X_min)
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model_min = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=10)
            model_min.fit(X_min_scaled, y_min)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            min_model_file = f'historical_minimum_model_{timestamp}.pkl'
            min_scaler_file = f'historical_minimum_scaler_{timestamp}.pkl'
            min_features_file = f'historical_minimum_features_{timestamp}.pkl'
            
            with open(min_model_file, 'wb') as f:
                pickle.dump(model_min, f)
            
            with open(min_scaler_file, 'wb') as f:
                pickle.dump(scaler_min, f)
            
            with open(min_features_file, 'wb') as f:
                pickle.dump(feature_names_min, f)
            
            print(f"   ‚úÖ –ú–æ–¥–µ–ª—å –º–∏–Ω–∏–º—É–º–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {min_model_file}")
            print(f"   üìä –î–∞–Ω–Ω—ã—Ö: {len(X_min)} –æ–±—Ä–∞–∑—Ü–æ–≤, {len(feature_names_min)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            print(f"   ‚úÖ –ü—Ä–∏–±—ã–ª—å–Ω—ã—Ö: {sum(y_min)} ({sum(y_min)/len(y_min)*100:.1f}%)")
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –º–∞–∫—Å–∏–º—É–º–æ–≤
        if len(self.maximums_database) >= 50:
            print("\nüî∫ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –º–∞–∫—Å–∏–º—É–º–æ–≤...")
            
            X_max = []
            y_max = []
            feature_names_max = list(self.maximums_database[0]['features'].keys())
            
            for maximum in self.maximums_database:
                features_list = [maximum['features'][name] for name in feature_names_max]
                X_max.append(features_list)
                y_max.append(1 if maximum['is_profitable_exit'] else 0)
            
            X_max = np.array(X_max)
            y_max = np.array(y_max)
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
            scaler_max = StandardScaler()
            X_max_scaled = scaler_max.fit_transform(X_max)
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model_max = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=10)
            model_max.fit(X_max_scaled, y_max)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            max_model_file = f'historical_maximum_model_{timestamp}.pkl'
            max_scaler_file = f'historical_maximum_scaler_{timestamp}.pkl'
            max_features_file = f'historical_maximum_features_{timestamp}.pkl'
            
            with open(max_model_file, 'wb') as f:
                pickle.dump(model_max, f)
            
            with open(max_scaler_file, 'wb') as f:
                pickle.dump(scaler_max, f)
            
            with open(max_features_file, 'wb') as f:
                pickle.dump(feature_names_max, f)
            
            print(f"   ‚úÖ –ú–æ–¥–µ–ª—å –º–∞–∫—Å–∏–º—É–º–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {max_model_file}")
            print(f"   üìä –î–∞–Ω–Ω—ã—Ö: {len(X_max)} –æ–±—Ä–∞–∑—Ü–æ–≤, {len(feature_names_max)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            print(f"   ‚úÖ –•–æ—Ä–æ—à–∏—Ö –≤—ã—Ö–æ–¥–æ–≤: {sum(y_max)} ({sum(y_max)/len(y_max)*100:.1f}%)")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        metadata = {
            'training_period': f"{self.training_start.strftime('%Y-%m-%d')} - {self.training_end.strftime('%Y-%m-%d')}",
            'testing_period': f"{self.testing_start.strftime('%Y-%m-%d')} - –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è",
            'symbols': self.symbols,
            'minimums_count': len(self.minimums_database),
            'maximums_count': len(self.maximums_database),
            'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'model_type': 'RandomForestClassifier',
            'scaler_type': 'StandardScaler'
        }
        
        metadata_file = f'historical_training_metadata_{timestamp}.json'
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"\nüíæ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metadata_file}")
    
    def run_historical_training(self):
        """–ó–∞–ø—É—Å–∫ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
        print("üöÄ –ó–ê–ü–£–°–ö –ò–°–¢–û–†–ò–ß–ï–°–ö–û–ì–û –û–ë–£–ß–ï–ù–ò–Ø")
        print("=" * 60)
        
        # 1. –°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        self.collect_historical_data()
        
        if not self.minimums_database and not self.maximums_database:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ")
            return
        
        # 2. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        self.train_historical_models()
        
        print(f"\n‚úÖ –ò–°–¢–û–†–ò–ß–ï–°–ö–û–ï –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        print(f"üìä –ú–∏–Ω–∏–º—É–º–æ–≤: {len(self.minimums_database)}")
        print(f"üìä –ú–∞–∫—Å–∏–º—É–º–æ–≤: {len(self.maximums_database)}")
        print(f"üß† –ú–æ–¥–µ–ª–∏ –≥–æ—Ç–æ–≤—ã –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö 2025 –≥–æ–¥–∞")

if __name__ == "__main__":
    trainer = HistoricalTrainer()
    trainer.run_historical_training()
