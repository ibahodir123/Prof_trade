#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""
import os
import json
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
import pickle

def create_simple_model():
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å LSTM"""
    model = tf.keras.Sequential([
        tf.keras.layers.LSTM(32, return_sequences=True, input_shape=(12, 5)),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.LSTM(16, return_sequences=False),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(5, activation='softmax')  # 5 –∫–ª–∞—Å—Å–æ–≤
    ])
    
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    return model

def prepare_simple_features(df):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"""
    features = pd.DataFrame()
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    features['close'] = df['close']
    features['volume'] = df['volume']
    features['high'] = df['high']
    features['low'] = df['low']
    features['rsi'] = df.get('rsi', 50)  # –ï—Å–ª–∏ RSI –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º 50
    
    return features.fillna(0)

def create_simple_sequences(features, targets, sequence_length=12):
    """–°–æ–∑–¥–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è LSTM"""
    X, y = [], []
    
    for i in range(sequence_length, len(features)):
        X.append(features[i-sequence_length:i].values)
        y.append(targets[i])
    
    return np.array(X), np.array(y)

def simple_train():
    """–ü—Ä–æ—Å—Ç–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    print("üöÄ –ü–†–û–°–¢–û–ï –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("=" * 40)
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    print("üìä –°–æ–∑–¥–∞—é —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ...")
    
    np.random.seed(42)
    n_samples = 1000
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    data = {
        'close': np.random.randn(n_samples).cumsum() + 100,
        'volume': np.random.exponential(1000, n_samples),
        'high': np.random.randn(n_samples).cumsum() + 102,
        'low': np.random.randn(n_samples).cumsum() + 98,
        'rsi': np.random.uniform(20, 80, n_samples)
    }
    
    df = pd.DataFrame(data)
    
    # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–∫–ª–∞—Å—Å—ã —Ä–æ—Å—Ç–∞)
    df['price_change'] = df['close'].pct_change(12).fillna(0)
    
    def categorize_growth(change):
        if change > 0.2:
            return 4  # –í–∑—Ä—ã–≤–Ω–æ–π —Ä–æ—Å—Ç
        elif change > 0.1:
            return 3  # –í—ã—Å–æ–∫–∏–π —Ä–æ—Å—Ç
        elif change > 0.05:
            return 2  # –£–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç
        elif change > 0:
            return 1  # –ù–µ–±–æ–ª—å—à–æ–π —Ä–æ—Å—Ç
        else:
            return 0  # –ü–∞–¥–µ–Ω–∏–µ/–±–æ–∫–æ–≤–∏–∫
    
    df['growth_category'] = df['price_change'].apply(categorize_growth)
    df['is_shooting_star'] = (df['growth_category'] >= 3).astype(int)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    print(f"üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {df['growth_category'].value_counts().sort_index().to_dict()}")
    print(f"üéØ –°—Ç—Ä–µ–ª—è—é—â–∏—Ö –º–æ–º–µ–Ω—Ç–æ–≤: {df['is_shooting_star'].sum()}")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    print("\nüîß –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—é –ø—Ä–∏–∑–Ω–∞–∫–∏...")
    features = prepare_simple_features(df)
    targets = df['growth_category'].values
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    print("üìä –°–æ–∑–¥–∞—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
    X, y = create_simple_sequences(features, targets)
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(X)} –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π")
    print(f"üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {X.shape}")
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    print("üîß –ù–æ—Ä–º–∞–ª–∏–∑—É—é –¥–∞–Ω–Ω—ã–µ...")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    print("üß† –°–æ–∑–¥–∞—é –º–æ–¥–µ–ª—å...")
    model = create_simple_model()
    
    # –û–±—É—á–µ–Ω–∏–µ
    print("üöÄ –ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ...")
    history = model.fit(
        X_scaled, y,
        epochs=10,
        batch_size=32,
        validation_split=0.2,
        verbose=1
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    print("üíæ –°–æ—Ö—Ä–∞–Ω—è—é –º–æ–¥–µ–ª—å...")
    model.save("simple_shooting_star_model.h5")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫–µ–π–ª–µ—Ä
    with open("simple_shooting_star_scaler.pkl", 'wb') as f:
        pickle.dump(scaler, f)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    metadata = {
        "sequence_length": 12,
        "prediction_horizon": 12,
        "features": list(features.columns),
        "classes": ["fall", "small_growth", "medium_growth", "high_growth", "explosive_growth"],
        "training_samples": len(X),
        "accuracy": float(history.history['val_accuracy'][-1])
    }
    
    with open("simple_shooting_star_metadata.json", 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
    print(f"üìä –¢–æ—á–Ω–æ—Å—Ç—å: {history.history['val_accuracy'][-1]:.2%}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    print("\nüéØ –¢–µ—Å—Ç–∏—Ä—É—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ...")
    test_sample = X_scaled[-1:].reshape(1, 12, 5)
    prediction = model.predict(test_sample, verbose=0)
    
    predicted_class = np.argmax(prediction[0])
    confidence = np.max(prediction[0])
    
    print(f"   - –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {predicted_class}")
    print(f"   - –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1%}")
    print(f"   - –í—Å–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: {prediction[0]}")
    
    print("\nüéâ –ì–û–¢–û–í–û! –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞!")
    print("\nüìÅ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    print("   - simple_shooting_star_model.h5")
    print("   - simple_shooting_star_scaler.pkl")
    print("   - simple_shooting_star_metadata.json")
    
    return True

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üß† –ü–†–û–°–¢–û–ï –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –°–¢–†–ï–õ–Ø–Æ–©–ò–• –ú–û–ù–ï–¢")
    print("=" * 60)
    
    success = simple_train()
    
    if success:
        print("\n‚úÖ –£–°–ü–ï–®–ù–û! –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        print("\nüìã –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("   - python demo_saved_model.py (–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è)")
        print("   - python shooting_star_bot.py (–∑–∞–ø—É—Å–∫ –±–æ—Ç–∞)")
    else:
        print("\n‚ùå –û–ë–£–ß–ï–ù–ò–ï –ù–ï –£–î–ê–õ–û–°–¨")

if __name__ == "__main__":
    main()

